{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# go wide screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version implements a \n",
    "# spectrally variing detection threshold.\n",
    "import time\n",
    "import numpy as np\n",
    "import spectrum\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "import sys\n",
    "from astropy.io import ascii\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "#from imageio import imread\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import maxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(s):\n",
    "    print(s)\n",
    "    return s + \"\\n\"\n",
    "\n",
    "\n",
    "def grow_segment(c, outmap, x, y, z, threshold, label):\n",
    "    # Non object oriented version\n",
    "    def get_children(zyx, shape):\n",
    "        maxz, maxy, maxx = shape\n",
    "        z, y, x = zyx\n",
    "        children = []\n",
    "        ddx = [-1,0,1]\n",
    "        ddy = [-1,0,1]\n",
    "        ddz = [-1,0,1]\n",
    "        #ddz = [0]\n",
    "        for dx in ddx:\n",
    "            for dy in ddy:\n",
    "                for dz in ddz:\n",
    "                    if not dx == dy == dz == 0:\n",
    "                        newx, newy, newz = x+dx, y+dy, z+dz\n",
    "                        if newx >= 0 and newx < maxx\\\n",
    "                            and newy >= 0 and newy < maxy\\\n",
    "                            and newz >= 0 and newz < maxz:\n",
    "                               children.append( (newz, newy, newx) ) \n",
    "        return children\n",
    "\n",
    "    pixel_list = []\n",
    "    stack = [(z,y,x)]\n",
    "    outmap[(z,y,x)] = label\n",
    "\n",
    "    maxiter = 1e6\n",
    "    iter = 0\n",
    "    while len(stack) > 0: \n",
    "        pm = stack.pop()\n",
    "        pp = get_children(pm, c.shape)\n",
    "        for p in pp:\n",
    "            if c[p] >= threshold and  outmap[p] == 0: # pixel that are labeled 0 have not been visited yet\n",
    "                stack.append(p)\n",
    "                outmap[p] = label\n",
    "            elif c[p] < threshold and  outmap[p] == 0:\n",
    "                outmap[p] = -1 # label pixel with -1 if they have beed visited already\n",
    "        iter += 1\n",
    "        if iter > maxiter:\n",
    "            break\n",
    "\n",
    "    return outmap#pixel_list            \n",
    "\n",
    "\n",
    "def build_map(ww, c, sigma_detect_threshold, sigma_grow_threshold, noise_model):\n",
    "    # run cloud growth algorithm on all pixels above detection threshold\n",
    "    # try to be intelligent, only loop over pixels that exceed detection threshold\n",
    "    ii = (c.swapaxes(2,0) > np.polyval(noise_model, ww) * sigma_detect_threshold ).swapaxes(2,0)\n",
    "    \n",
    "    \n",
    "    N =  (np.sum(ii))\n",
    "    print(\"{} pixel above detection threshold\".format(N))\n",
    "\n",
    "    outmap = np.zeros_like(c, dtype=int)\n",
    "\n",
    "    zz,yy,xx = [np.arange(s, dtype=int) for s in c.shape]\n",
    "    YY,ZZ,XX = np.meshgrid(yy, zz, xx)\n",
    "\n",
    "    label = 1\n",
    "    for i, (x,y,z) in enumerate( zip(XX[ii], YY[ii], ZZ[ii] ) )  :  \n",
    "        if outmap[z,y,x] == 0:\n",
    "            pp(\"### {} z={} ###\".format(i,z))\n",
    "            print(x,y,z, outmap[z,y,x])\n",
    "            #outmap = build_map2(c, outmap, x,y,z, threshold = grow_threshold, label=label)\n",
    "\n",
    "            summary = \"\"\n",
    "            summary += pp(\"Building map starting with pixel {} out of {} that exceeds threshold...\".format(i,N))\n",
    "            start_time = time.time()\n",
    "            #print(\"{} labeled pixels on map\".format( np.nansum( (outmap > 0).flatten())) )\n",
    "            \n",
    "            # Here we set to which threshold a region shoudl be grown.\n",
    "            # note that this is not stricly correct, the threshold should very also inside\n",
    "            # grow_segment as function of wavelength. Here we will just rely on this\n",
    "            # being a slowly variing function.\n",
    "            threshold = np.polyval(noise_model, ww[z]) * sigma_grow_threshold\n",
    "            print(\"grow_threshold = \", threshold)\n",
    "            outmap = grow_segment(c, outmap, x,y,z, threshold, label=label)\n",
    "            time_to_build = time.time() - start_time\n",
    "            summary += pp(\"Time to build map: {:.4e} s\".format(time_to_build))\n",
    "\n",
    "            print(\"{} labeled pixels on map\".format( np.nansum( (outmap > 0).flatten())) )\n",
    "            print(\"{} untouched pixels on map\".format( np.nansum( (outmap == 0).flatten())) )\n",
    "\n",
    "        label += 1\n",
    "\n",
    "        if i > 1e6:\n",
    "            break\n",
    "    #print (cnt)\n",
    "    return outmap\n",
    "\n",
    "\n",
    "def filter_minsize(outmap, minsize):\n",
    "    # filter regions with too small volume \n",
    "    rr = np.sort( np.unique( outmap.flatten() ) )\n",
    "    for r in rr:\n",
    "        if not r > 0:\n",
    "            continue\n",
    "        N = np.sum( outmap == r )\n",
    "        #print(\"{} : N = {}\".format(r, N))\n",
    "        if N < minsize:\n",
    "            outmap[outmap == r] = -1  \n",
    "    rr = np.sort( np.unique( outmap.flatten() ) )\n",
    "    \n",
    "    # relabel\n",
    "    for i,r in enumerate(rr[rr>0]):\n",
    "        outmap[outmap == r] = i + 1\n",
    "\n",
    "    rr = np.sort( np.unique( outmap.flatten() ) )\n",
    "    print(\"{} regions survive size cut\".format( len(rr[rr>0]) ))\n",
    "\n",
    "    return outmap\n",
    "\n",
    "\n",
    "\n",
    "def save_map(outmap, fmapout):\n",
    "    w = wcs.WCS(s.hdu)\n",
    "    # save map\n",
    "    f = np.zeros_like(c)\n",
    "    f[outmap > 0] = c[outmap > 0]\n",
    "    wcs_header =  w.to_header()\n",
    "\n",
    "\n",
    "    h = fits.PrimaryHDU(data=outmap, header=s.hdu.header)\n",
    "    for k in wcs_header:\n",
    "        h.header[k] = wcs_header[k]\n",
    "    hdu = fits.HDUList(h)\n",
    "\n",
    "    # save map filtered data\n",
    "    f = np.zeros_like(c)\n",
    "    f[outmap > 0] = c[outmap > 0]\n",
    "    h = fits.ImageHDU(data=f, header=s.hdu.header, name = \"filtered_data\")\n",
    "    for k in wcs_header:\n",
    "        h.header[k] = wcs_header[k]\n",
    "\n",
    "    hdu.append(h)\n",
    "\n",
    "    # save shells \n",
    "    f = np.zeros_like(c)\n",
    "    f[outmap == -1] = c[outmap == -1]\n",
    "\n",
    "    h = fits.ImageHDU(data=f, header=s.hdu.header, name = \"shells\")\n",
    "    for k in wcs_header:\n",
    "        h.header[k] = wcs_header[k]\n",
    "    hdu.append(h)\n",
    "\n",
    "    hdu.writeto(fmapout, overwrite=True)\n",
    "    print(\"Wrote {}.\".format(fmapout))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fast graph construction, no color or distance based weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcube = \"sf2outcube_20180618v017_024_pca.fits.gz\"\n",
    "fnoisemodel = \"sf2outcube_20180618v017_024_pca.detect_noise_model\"\n",
    "workdir = \"/work/04287/mxhf/maverick/hetdex/cubes\"\n",
    "datadir = os.path.join(workdir, \"\")\n",
    "\n",
    "w = 12.\n",
    "wz = .05\n",
    "dscale = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "s = spectrum.readSpectrum(os.path.join(datadir, fcube))\n",
    "ww = s.grid()\n",
    "\n",
    "# read noise model\n",
    "noise_model = np.loadtxt(os.path.join(datadir, fnoisemodel) )\n",
    "\n",
    "# scale date by noise\n",
    "c = s.data\n",
    "\n",
    "c = dscale * np.multiply(c.T, 1./np.polyval(noise_model, ww )).T\n",
    "\n",
    "#c = c[118-5:118+6] # for faster testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph with integer capacities.\n",
    "# best guess for number of nodes and edges\n",
    "nnodes = len( c.flatten() )\n",
    "nedges = len( c.flatten() )*26 + 2*len( c.flatten() )\n",
    "g = maxflow.Graph[float](nnodes, nedges )\n",
    "\n",
    "nodes = g.add_grid_nodes(c.shape)\n",
    "\n",
    "# connection weights based on Euclidian distances\n",
    "structure = np.array([ w*wz* np.array([[.58, .7, .58],\n",
    "                        [.7, 1, .7],\n",
    "                        [.58, .7, .58]]),\n",
    "                       w*np.array([[.7, 1, .7],\n",
    "                        [1, 0, 1],\n",
    "                        [.7, 1, .7]]),\n",
    "                       w*wz*np.array([[.58, .7, .58],\n",
    "                        [.7, 1, .7],\n",
    "                        [.58, .7, .58]]) ])\n",
    "\n",
    "g.add_grid_edges(nodes, structure=structure)\n",
    "g.add_grid_tedges(nodes, c, 1.-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum flow.\n",
    "g.maxflow()\n",
    "\n",
    "# Get the segments.\n",
    "sgm = g.get_grid_segments(nodes)\n",
    "\n",
    "# The labels should be 1 where sgm is False and 0 otherwise.\n",
    "img2 = np.int_(np.logical_not(sgm))\n",
    "# Show the result.\n",
    "cout = img2.reshape(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subcube = c[118-2:118+3]\n",
    "#subcout = cout[118-2:118+3]\n",
    "subcube = c\n",
    "subcout = cout\n",
    "N = subcube.shape[0]\n",
    "if N < 15:\n",
    "    f = plt.figure(figsize=[15,10])\n",
    "    for i in range(N):\n",
    "        plt.subplot(1,N,i+1)\n",
    "        plt.imshow(subcube[i]/dscale, origin='bottom', interpolation='none',vmin=0., vmax=2.)\n",
    "\n",
    "    f = plt.figure(figsize=[15,10])\n",
    "    for i in range(N):\n",
    "        plt.subplot(1,N,i+1)\n",
    "        plt.imshow(subcout[i], origin='bottom', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = s.hdu\n",
    "h.data = cout\n",
    "h.writeto(os.path.join(datadir, \"ct\" + fcube), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
